{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piachouaifaty/CSC375_OperatingSystems/blob/master/GA_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-Up"
      ],
      "metadata": {
        "id": "2Mydx614kKH4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "WB3UFVk2yJzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gc\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from itertools import cycle\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers.core import Dropout, Activation\n",
        "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, \\\n",
        "     Dense, Input, Activation, Dropout, GlobalAveragePooling2D, AveragePooling2D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import cv2\n",
        "from cv2 import imread, resize # manipulating the images\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
        "from keras import backend as K\n",
        "import itertools\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from datetime import datetime\n",
        "\n",
        "import glob\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "#!pip install fast_ml\n",
        "#from fast_ml.model_development import train_valid_test_split\n",
        "import sklearn\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "import statistics as st\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from re import M\n",
        "\n",
        "#!pip3 install pygad\n",
        "import pygad"
      ],
      "metadata": {
        "id": "3X0CxFwGw3OS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037efe5a-02e7-451a-fb29-6c66f8351211"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygad\n",
            "  Downloading pygad-2.19.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from pygad) (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from pygad) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pygad) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->pygad) (4.38.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.15.0)\n",
            "Installing collected packages: pygad\n",
            "Successfully installed pygad-2.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drive mounting"
      ],
      "metadata": {
        "id": "8IuMDDaduKcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jpw2fc6s358",
        "outputId": "1e7d361a-4c30-40e6-c1e8-80085de99724"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path setup"
      ],
      "metadata": {
        "id": "4XSrMb0nuJBV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R_66KK041Br1"
      },
      "outputs": [],
      "source": [
        "results_skin_dir = os.path.join('..', '/content/drive/MyDrive/Kaggle/skin_results')\n",
        "base_skin_dir = os.path.join('..', '/content/drive/MyDrive/Kaggle/skin')\n",
        "\n",
        "results_skin_dir = os.path.join('..', '/content/drive/MyDrive/Kaggle/skin_results')\n",
        "base_skin_dir = os.path.join('..', '/content/drive/MyDrive/Kaggle/skin')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metadata"
      ],
      "metadata": {
        "id": "o0ZlQbV2uGJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_skin = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))"
      ],
      "metadata": {
        "id": "Bc8bN_c5s_Ij"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
        "print('All Labels ({}): {}'.format(len(all_labels), all_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trz_hTNEtDWF",
        "outputId": "c0c82d56-a4fb-45ba-ccb9-d9d953be7b2e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Labels (7): ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "lesion_ID_dict = {\n",
        "    'nv': 0,\n",
        "    'mel': 1,\n",
        "    'bkl': 2,\n",
        "    'bcc': 3,\n",
        "    'akiec': 4,\n",
        "    'vasc': 5,\n",
        "    'df': 6\n",
        "}\n",
        "\n",
        "# Lesion and it's abbriv.\n",
        "lesion_names = ['Melanocytic nevi','Melanoma','Benign keratosis-like lesions ',\n",
        "               'Basal cell carcinoma','Actinic keratoses','Vascular lesions',\n",
        "               'Dermatofibroma']\n",
        "lesion_names_short = ['nv','mel','bkl','bcc','akiec','vasc','df']\n",
        "\n",
        "# Maping the lesion type and ID to a dict.\n",
        "df_skin['lesion_type']=df_skin['dx'].map(lesion_type_dict)\n",
        "df_skin['lesion_ID'] = df_skin['dx'].map(lesion_ID_dict)"
      ],
      "metadata": {
        "id": "nn3YquuntGnY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train/Test/Val Split"
      ],
      "metadata": {
        "id": "uPLBkKsatTQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.load(os.path.join(base_skin_dir,'x.csv.npy'))\n",
        "y = np.load(os.path.join(base_skin_dir,'y.csv.npy'))\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# convert y (targets) array as required by softmax activation function\n",
        "y_t = to_categorical(y, num_classes = 7)\n",
        "\n",
        "print('dataset shape', x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTDsimUmtW-8",
        "outputId": "2893c4a6-542a-47c8-d652-7c617466988a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape (26565, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train-test-val\n",
        "X_train, X_rem, y_train, y_rem = train_test_split(x, \n",
        "                                                  y_t, \n",
        "                                                  train_size=0.7, \n",
        "                                                  random_state=50)\n",
        "\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, \n",
        "                                                    y_rem, \n",
        "                                                    test_size=0.33, \n",
        "                                                    random_state=50) # 0.5 x 0.2 = 0.1\n",
        "\n",
        "print('x Train dataset shape', X_train.shape)\n",
        "print('x Val dataset shape', X_valid.shape)\n",
        "print('x test dataset shape', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTQcvqPktaTr",
        "outputId": "0e092891-c079-4b1f-ac49-451808d8f32e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x Train dataset shape (18595, 100, 100, 3)\n",
            "x Val dataset shape (5339, 100, 100, 3)\n",
            "x test dataset shape (2631, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Blending holdout set\n",
        "X_valid1, X_holdout, y_valid1, y_holdout = train_test_split(X_valid, \n",
        "                                                    y_valid, \n",
        "                                                    test_size=0.5, \n",
        "                                                    random_state=20)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X validation: \", X_valid.shape)\n",
        "print(\"X test: \", X_test.shape)\n",
        "print(\"-------------\")\n",
        "print(\"X validation2: \", X_valid1.shape)\n",
        "print(\"X holdout: \",X_holdout.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEzeQkEjtdm8",
        "outputId": "8a592f1a-ea8e-4c90-f682-c3cd5d6f866c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train:  (18595, 100, 100, 3)\n",
            "X validation:  (5339, 100, 100, 3)\n",
            "X test:  (2631, 100, 100, 3)\n",
            "-------------\n",
            "X validation2:  (2669, 100, 100, 3)\n",
            "X holdout:  (2670, 100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trained models"
      ],
      "metadata": {
        "id": "neb7PrwLxvt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "B1rywfziTg6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_models = pd.read_csv(os.path.join(results_skin_dir, 'modelfilenames.csv'))\n",
        "df_models\n",
        "#this file contains all the trained model filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "GTMftswExxiV",
        "outputId": "ad8901bd-46d6-4453-9b19-353e5329dca9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Model   timestamp                 full  \\\n",
              "0        Model 1 - Custom CNN  1676796445  1676796445_model.h5   \n",
              "1        Model 2 - Custom CNN  1676816510  1676816510_model.h5   \n",
              "2          Model 3 - Xception  1676839766  1676839766_model.h5   \n",
              "3        Model 4 - Custom CNN  1676842274  1676842274_model.h5   \n",
              "4          Model 5 - Xception  1676913088  1676913088_model.h5   \n",
              "5            Model 6 - Resnet  1676936146  1676936146_model.h5   \n",
              "6       Model 7 - DenseNet201  1676987763  1676987763_model.h5   \n",
              "7       Model 8 - InceptionV3  1676997761  1676997761_model.h5   \n",
              "8             Model 9 - VGG19  1677017458  1677017458_model.h5   \n",
              "9  Model 10 - InceptionResnet  1677026677  1677026677_model.h5   \n",
              "\n",
              "                       bagging                      blending  \n",
              "0  1676796445_bagging_model.h5  1676796445_blending_model.h5  \n",
              "1  1676816510_bagging_model.h5  1676816510_blending_model.h5  \n",
              "2  1676839766_bagging_model.h5  1676839766_blending_model.h5  \n",
              "3  1676842274_bagging_model.h5  1676842274_blending_model.h5  \n",
              "4  1676913088_bagging_model.h5  1676913088_blending_model.h5  \n",
              "5  1676936146_bagging_model.h5  1676936146_blending_model.h5  \n",
              "6  1676987763_bagging_model.h5  1676987763_blending_model.h5  \n",
              "7  1676997761_bagging_model.h5  1676997761_blending_model.h5  \n",
              "8  1677017458_bagging_model.h5  1677017458_blending_model.h5  \n",
              "9  1677026677_bagging_model.h5  1677026677_blending_model.h5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6b28fd5e-b2f1-48c3-896d-542adf2711cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>full</th>\n",
              "      <th>bagging</th>\n",
              "      <th>blending</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Model 1 - Custom CNN</td>\n",
              "      <td>1676796445</td>\n",
              "      <td>1676796445_model.h5</td>\n",
              "      <td>1676796445_bagging_model.h5</td>\n",
              "      <td>1676796445_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model 2 - Custom CNN</td>\n",
              "      <td>1676816510</td>\n",
              "      <td>1676816510_model.h5</td>\n",
              "      <td>1676816510_bagging_model.h5</td>\n",
              "      <td>1676816510_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Model 3 - Xception</td>\n",
              "      <td>1676839766</td>\n",
              "      <td>1676839766_model.h5</td>\n",
              "      <td>1676839766_bagging_model.h5</td>\n",
              "      <td>1676839766_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Model 4 - Custom CNN</td>\n",
              "      <td>1676842274</td>\n",
              "      <td>1676842274_model.h5</td>\n",
              "      <td>1676842274_bagging_model.h5</td>\n",
              "      <td>1676842274_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model 5 - Xception</td>\n",
              "      <td>1676913088</td>\n",
              "      <td>1676913088_model.h5</td>\n",
              "      <td>1676913088_bagging_model.h5</td>\n",
              "      <td>1676913088_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Model 6 - Resnet</td>\n",
              "      <td>1676936146</td>\n",
              "      <td>1676936146_model.h5</td>\n",
              "      <td>1676936146_bagging_model.h5</td>\n",
              "      <td>1676936146_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Model 7 - DenseNet201</td>\n",
              "      <td>1676987763</td>\n",
              "      <td>1676987763_model.h5</td>\n",
              "      <td>1676987763_bagging_model.h5</td>\n",
              "      <td>1676987763_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Model 8 - InceptionV3</td>\n",
              "      <td>1676997761</td>\n",
              "      <td>1676997761_model.h5</td>\n",
              "      <td>1676997761_bagging_model.h5</td>\n",
              "      <td>1676997761_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Model 9 - VGG19</td>\n",
              "      <td>1677017458</td>\n",
              "      <td>1677017458_model.h5</td>\n",
              "      <td>1677017458_bagging_model.h5</td>\n",
              "      <td>1677017458_blending_model.h5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Model 10 - InceptionResnet</td>\n",
              "      <td>1677026677</td>\n",
              "      <td>1677026677_model.h5</td>\n",
              "      <td>1677026677_bagging_model.h5</td>\n",
              "      <td>1677026677_blending_model.h5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b28fd5e-b2f1-48c3-896d-542adf2711cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b28fd5e-b2f1-48c3-896d-542adf2711cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b28fd5e-b2f1-48c3-896d-542adf2711cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_models['full'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ubQaEbnw24ZW",
        "outputId": "441f563a-47a2-4948-926b-25f279a0ef31"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1676796445_model.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function load our models\n",
        "def load_trained_model(modeltype, modelnumber):\n",
        "  path = os.path.join(results_skin_dir, df_models[modeltype][modelnumber-1])\n",
        "  print(path)  \n",
        "  m = load_model(path)\n",
        "  return m"
      ],
      "metadata": {
        "id": "cqOWecWhRNUj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing predictions (DO NOT RE-RUN)"
      ],
      "metadata": {
        "id": "uFzkpHpxTj-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the models will be inputted into the GA as follows:\n",
        "#list: [model_name, predictions_test, accuracy_full, bagging_predictions_test, bagging_accuracy, blending_predictions_holdout, bagging_accuracy]\n",
        "#model[0]: model name"
      ],
      "metadata": {
        "id": "ER2f83_cBPqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model(modelnumber, X_test, y_test, X_holdout, y_holdout):\n",
        "  pre = False\n",
        "  if modelnumber == 3:\n",
        "    pre = True\n",
        "    print(\"Model 3, now generating preprocessing functions\")\n",
        "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "    test_datagen.fit(X_test)\n",
        "    test_generator = test_datagen.flow(X_test, y_test)\n",
        "    holdout_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "    holdout_datagen.fit(X_holdout)\n",
        "    holdout_generator = holdout_datagen.flow(X_holdout, y_holdout)\n",
        "\n",
        "  model_types = [\"full\", \"bagging\", \"blending\"]\n",
        "  mod_list = []\n",
        "  mod_list.append(\"model\"+str(modelnumber))\n",
        "\n",
        "  for modtype in model_types:\n",
        "    print(\"Now loading model\", modelnumber, modtype)\n",
        "    model = load_trained_model(modtype, modelnumber)\n",
        "    if pre:\n",
        "      if modtype==\"blending\":\n",
        "        print(\"Now predicting on holdout set with preprocessing\")\n",
        "        y_pred = model.predict(preprocess_input(X_holdout))\n",
        "        print(\"Now evaluating on test set\")\n",
        "        scores = model.evaluate(test_generator, verbose = 1)\n",
        "        accuracy = scores[1]\n",
        "      else:\n",
        "        print(\"Now predicting on test set with preprocessing\")\n",
        "        y_pred = model.predict(preprocess_input(X_test))\n",
        "        print(\"Now evaluating on test set\")\n",
        "        scores = model.evaluate(test_generator, verbose = 1)\n",
        "        accuracy = scores[1]\n",
        "      print(y_pred)\n",
        "      print(\"Model\", modelnumber, modtype, \"accuracy:\", accuracy)\n",
        "      mod_list.append(y_pred)\n",
        "      mod_list.append(accuracy)\n",
        "      print(\"--------------------------------\")\n",
        "    else:\n",
        "      if modtype==\"blending\":\n",
        "        print(\"Now predicting on holdout set\")\n",
        "        y_pred = model.predict(X_holdout)\n",
        "      else:\n",
        "        print(\"Now predicting on test set\")\n",
        "        y_pred = model.predict(X_test)\n",
        "      #general model accuracy is always evaluated on the test set\n",
        "      #accuracies needed for weighted voting\n",
        "      print(\"Now evaluating on test set\")\n",
        "      scores = model.evaluate(X_test, y_test, verbose = 1)\n",
        "      accuracy = scores[1]\n",
        "      mod_list.append(y_pred)\n",
        "      mod_list.append(accuracy)\n",
        "      print(y_pred)\n",
        "      print(\"Model\", modelnumber, modtype, \"accuracy: \", accuracy)\n",
        "      print(\"--------------------------------\")\n",
        "  return mod_list\n",
        "\n",
        "#PREDICTION for models that require preprocessing\n",
        "#model 3\n",
        "#y_pred = model.predict(preprocess_input(X_test))\n",
        "\n",
        "#EVALUATION for models that require preprocessing\n",
        "\n",
        "#test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "#test_datagen.fit(X_test)\n",
        "#test_generator = test_datagen.flow(X_test, y_test)\n",
        "#scores = model.evaluate(test_generator, verbose = 1)\n",
        "#print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
      ],
      "metadata": {
        "id": "rPdgGaNYA42U"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#m1 = generate_model(1, X_test, y_test, X_holdout, y_holdout)\n",
        "#m2 = generate_model(2, X_test, y_test, X_holdout, y_holdout)\n",
        "#m3 = generate_model(3, X_test, y_test, X_holdout, y_holdout)\n",
        "#m4 = generate_model(4, X_test, y_test, X_holdout, y_holdout)\n",
        "#m5 = generate_model(5, X_test, y_test, X_holdout, y_holdout)\n",
        "#m6 = generate_model(6, X_test, y_test, X_holdout, y_holdout)\n",
        "#m7 = generate_model(7, X_test, y_test, X_holdout, y_holdout)\n",
        "#m8 = generate_model(8, X_test, y_test, X_holdout, y_holdout)\n",
        "#m9 = generate_model(9, X_test, y_test, X_holdout, y_holdout)\n",
        "\n",
        "#BAGGING MODEL NEEDS RETRAINING\n"
      ],
      "metadata": {
        "id": "BAiTp4ZpBqAl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a3383d3-2699-4251-eaf0-c6f087f37d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now loading model 1 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676796445_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 8s 5ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 5ms/step - loss: 0.3989 - accuracy: 0.9160\n",
            "[[1.0000000e+00 2.6464586e-12 1.2870426e-13 ... 4.2029156e-17\n",
            "  1.0325957e-19 5.7178761e-18]\n",
            " [3.2583785e-01 6.7386419e-01 4.5232642e-05 ... 2.5078861e-04\n",
            "  1.5990624e-06 4.6272916e-08]\n",
            " [1.5828029e-04 5.2317153e-03 9.9460381e-01 ... 1.7378407e-07\n",
            "  5.2395812e-06 4.8535833e-09]\n",
            " ...\n",
            " [9.9935549e-01 1.3765309e-04 5.0599076e-04 ... 6.8605533e-07\n",
            "  7.5394766e-08 3.5044508e-08]\n",
            " [2.9784633e-08 3.0320324e-09 7.4011384e-09 ... 1.0000000e+00\n",
            "  2.2682413e-21 5.4195323e-16]\n",
            " [3.3333118e-04 9.9939966e-01 2.5037705e-05 ... 2.4186127e-04\n",
            "  6.4305622e-10 5.2439022e-09]]\n",
            "Model 1 full accuracy:  0.9160014986991882\n",
            "--------------------------------\n",
            "Now loading model 1 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676796445_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 1s 5ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 5ms/step - loss: 0.6779 - accuracy: 0.8309\n",
            "[[9.9995971e-01 3.8395643e-05 1.8926503e-06 ... 9.7280912e-09\n",
            "  2.3920421e-09 8.3479890e-11]\n",
            " [3.0249271e-03 9.9695033e-01 2.2730550e-05 ... 1.8990553e-06\n",
            "  1.6283588e-08 2.4699236e-08]\n",
            " [9.7319791e-03 5.0181288e-01 4.8765841e-01 ... 1.2786810e-04\n",
            "  4.0583263e-04 1.0825040e-05]\n",
            " ...\n",
            " [9.9548233e-01 3.0001474e-03 1.4795768e-03 ... 1.7547058e-05\n",
            "  1.2710311e-05 2.6171219e-06]\n",
            " [6.0683391e-08 1.2693229e-07 4.8923619e-07 ... 9.9999607e-01\n",
            "  1.7511415e-12 3.0159757e-08]\n",
            " [6.6816734e-05 9.9955362e-01 3.7677275e-04 ... 2.6969701e-06\n",
            "  4.5906676e-10 1.4330140e-10]]\n",
            "Model 1 bagging accuracy:  0.8308627605438232\n",
            "--------------------------------\n",
            "Now loading model 1 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676796445_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 1s 6ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 5ms/step - loss: 0.3183 - accuracy: 0.9042\n",
            "[[9.9999845e-01 1.9536350e-07 1.3553765e-06 ... 3.6723936e-13\n",
            "  1.5597146e-10 8.8029090e-10]\n",
            " [9.9525225e-01 1.5229877e-04 4.5380830e-03 ... 4.2610245e-07\n",
            "  2.1622095e-07 5.5444652e-05]\n",
            " [2.6348750e-19 8.2905950e-19 1.1112791e-13 ... 1.0000000e+00\n",
            "  2.7858760e-31 3.3611207e-19]\n",
            " ...\n",
            " [1.0954493e-05 2.8192997e-05 9.9995959e-01 ... 1.2561873e-06\n",
            "  7.4179209e-14 1.3195398e-10]\n",
            " [6.3071353e-04 9.9935430e-01 1.4894090e-05 ... 6.0239662e-09\n",
            "  1.0578909e-07 2.4926886e-10]\n",
            " [9.9990904e-01 3.9815528e-05 4.9117250e-05 ... 4.6446161e-10\n",
            "  6.5867226e-08 1.9636109e-06]]\n",
            "Model 1 blending accuracy:  0.9042189121246338\n",
            "--------------------------------\n",
            "Now loading model 2 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676816510_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 1s 7ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 1.2431 - accuracy: 0.6085\n",
            "[[9.99970555e-01 1.23601158e-05 1.52612938e-05 ... 4.20001638e-11\n",
            "  7.21720947e-11 1.51102233e-06]\n",
            " [6.52320385e-01 3.47285002e-01 3.94532632e-04 ... 2.00558912e-08\n",
            "  1.22963561e-16 6.31408675e-11]\n",
            " [2.21349359e-01 3.13839108e-01 4.64773923e-01 ... 8.32908285e-08\n",
            "  2.47239895e-10 3.60797567e-05]\n",
            " ...\n",
            " [7.12085485e-01 2.21347705e-01 6.64509684e-02 ... 4.80434974e-05\n",
            "  1.72529369e-11 5.26218828e-05]\n",
            " [1.94574431e-01 2.27194548e-01 2.88738430e-01 ... 1.15094766e-01\n",
            "  3.55372322e-04 3.73991914e-02]\n",
            " [5.45258410e-02 9.42739069e-01 2.73016351e-03 ... 4.90631646e-06\n",
            "  1.04146807e-24 2.71104472e-10]]\n",
            "Model 2 full accuracy:  0.6085138916969299\n",
            "--------------------------------\n",
            "Now loading model 2 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676816510_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 1.1636 - accuracy: 0.6150\n",
            "[[9.99933481e-01 3.14106946e-05 2.60409015e-05 ... 4.65898164e-09\n",
            "  5.17806598e-07 5.40218207e-06]\n",
            " [4.18651402e-01 5.79830348e-01 1.51738105e-03 ... 7.95091978e-07\n",
            "  1.40175317e-12 7.51226303e-10]\n",
            " [2.36324756e-03 7.05418050e-01 2.92217493e-01 ... 1.72588743e-09\n",
            "  1.96580804e-15 1.16244655e-06]\n",
            " ...\n",
            " [9.79919732e-01 1.19162425e-02 8.16387590e-03 ... 9.70978391e-08\n",
            "  6.72900091e-09 1.33525395e-08]\n",
            " [9.32045281e-02 1.65707648e-01 2.13418365e-01 ... 1.48980334e-01\n",
            "  3.90031328e-03 7.23944679e-02]\n",
            " [1.06738895e-01 8.42285097e-01 5.09735607e-02 ... 2.31339959e-06\n",
            "  1.10055605e-15 2.81312413e-08]]\n",
            "Model 2 bagging accuracy:  0.6149752736091614\n",
            "--------------------------------\n",
            "Now loading model 2 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676816510_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 1s 8ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 8ms/step - loss: 1.0375 - accuracy: 0.6553\n",
            "[[1.0000000e+00 1.2461469e-08 3.1427144e-10 ... 2.6165152e-19\n",
            "  1.8049938e-15 1.2812592e-14]\n",
            " [9.6264642e-01 1.4063902e-07 3.7353486e-02 ... 6.5653975e-18\n",
            "  0.0000000e+00 6.1271704e-10]\n",
            " [4.9028038e-03 1.1386724e-02 3.7285495e-01 ... 4.7435093e-01\n",
            "  5.7630961e-10 6.4344190e-02]\n",
            " ...\n",
            " [3.9747278e-03 5.0686747e-01 4.8915783e-01 ... 1.8056167e-09\n",
            "  0.0000000e+00 6.0119298e-11]\n",
            " [2.0880646e-04 4.6283066e-01 5.3696054e-01 ... 5.6447956e-17\n",
            "  0.0000000e+00 2.6088120e-17]\n",
            " [4.4906399e-01 1.9758768e-01 3.5333902e-01 ... 5.3550058e-09\n",
            "  5.8195035e-17 9.2588134e-06]]\n",
            "Model 2 blending accuracy:  0.655264139175415\n",
            "--------------------------------\n",
            "Model 3, now generating preprocessing functions\n",
            "Now loading model 3 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676839766_model.h5\n",
            "Now predicting on test set with preprocessing\n",
            "83/83 [==============================] - 4s 31ms/step\n",
            "Now evaluating on test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5534: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - 3s 29ms/step - loss: 1.2611 - accuracy: 0.6393\n",
            "[[9.95833755e-01 1.00981978e-07 1.02040094e-05 ... 5.18495871e-11\n",
            "  7.97825123e-06 4.14795196e-03]\n",
            " [5.05379438e-01 4.72618520e-01 9.32080671e-03 ... 1.37407606e-05\n",
            "  2.01628310e-07 5.93459226e-10]\n",
            " [2.40880325e-02 3.81933153e-01 5.93960941e-01 ... 3.53216723e-09\n",
            "  1.40633165e-05 5.06548581e-09]\n",
            " ...\n",
            " [9.60462987e-01 4.06610919e-03 3.54469195e-02 ... 1.22167867e-05\n",
            "  1.48180064e-07 8.76685657e-09]\n",
            " [1.02935908e-02 5.82752079e-02 5.13098836e-01 ... 1.07224591e-01\n",
            "  1.25103761e-04 9.18470207e-04]\n",
            " [2.81041879e-02 9.70836163e-01 2.39109053e-04 ... 6.41699065e-04\n",
            "  3.58882840e-10 4.12901970e-11]]\n",
            "Model 3 full accuracy: 0.6393006443977356\n",
            "--------------------------------\n",
            "Now loading model 3 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676839766_bagging_model.h5\n",
            "Now predicting on test set with preprocessing\n",
            "83/83 [==============================] - 3s 27ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 29ms/step - loss: 1.3154 - accuracy: 0.5975\n",
            "[[9.12322342e-01 1.49133652e-02 2.20610574e-02 ... 2.63880320e-05\n",
            "  1.34895890e-04 4.94370051e-02]\n",
            " [9.78420198e-01 2.03163456e-02 3.86451371e-04 ... 4.69024846e-04\n",
            "  3.23046777e-07 1.30252181e-06]\n",
            " [4.92075400e-04 3.70635763e-02 9.61271942e-01 ... 1.23526933e-09\n",
            "  6.35851347e-06 9.57754764e-08]\n",
            " ...\n",
            " [8.84001911e-01 5.42175630e-03 1.10573031e-01 ... 1.09294126e-06\n",
            "  1.13309120e-07 5.18920558e-07]\n",
            " [4.65913303e-02 4.97476831e-02 5.88786542e-01 ... 1.35049552e-01\n",
            "  1.28547745e-02 7.06562400e-03]\n",
            " [8.44107509e-01 1.22486979e-01 2.48903148e-02 ... 1.46908511e-04\n",
            "  6.03788430e-06 2.69264710e-05]]\n",
            "Model 3 bagging accuracy: 0.597491443157196\n",
            "--------------------------------\n",
            "Now loading model 3 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676839766_blending_model.h5\n",
            "Now predicting on holdout set with preprocessing\n",
            "84/84 [==============================] - 4s 32ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 32ms/step - loss: 1.1729 - accuracy: 0.6328\n",
            "[[9.99957800e-01 4.21753975e-05 8.79063933e-10 ... 6.92521062e-16\n",
            "  1.04935143e-14 1.05133422e-15]\n",
            " [9.99994636e-01 1.10196776e-08 5.06663537e-06 ... 2.62211124e-08\n",
            "  2.30606965e-08 1.14054703e-08]\n",
            " [2.11744793e-02 3.23600508e-02 2.16932610e-01 ... 4.63174462e-01\n",
            "  1.20319244e-04 9.81021225e-02]\n",
            " ...\n",
            " [5.32153249e-03 2.67229509e-02 9.67687488e-01 ... 2.66005838e-04\n",
            "  6.82430640e-11 1.36254957e-14]\n",
            " [3.55264060e-02 8.75312537e-02 8.76942277e-01 ... 4.84945244e-12\n",
            "  1.52332007e-07 2.29928434e-17]\n",
            " [9.93030965e-01 1.58454946e-04 6.70947274e-03 ... 2.54541650e-08\n",
            "  1.32316939e-06 6.28789348e-05]]\n",
            "Model 3 blending accuracy: 0.6328392028808594\n",
            "--------------------------------\n",
            "Now loading model 4 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676842274_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 0.8065 - accuracy: 0.8483\n",
            "[[9.9999511e-01 6.1586695e-07 1.7936301e-06 ... 2.1241372e-07\n",
            "  3.9550321e-07 1.0564933e-06]\n",
            " [1.4044391e-03 9.9856466e-01 3.5739888e-06 ... 7.9577126e-07\n",
            "  1.6726006e-05 2.5612542e-06]\n",
            " [1.3256328e-05 3.8888997e-01 6.1108994e-01 ... 1.5400913e-07\n",
            "  6.6284042e-07 3.6772510e-06]\n",
            " ...\n",
            " [9.9915731e-01 1.2808380e-04 6.5702264e-04 ... 1.0207442e-05\n",
            "  6.9968573e-06 1.5316289e-05]\n",
            " [1.4902678e-08 5.1438858e-09 2.5129870e-08 ... 9.9999976e-01\n",
            "  1.3030437e-07 2.2133591e-08]\n",
            " [3.3727986e-08 9.9989426e-01 3.5310173e-08 ... 1.0390573e-04\n",
            "  7.4231446e-07 6.4721654e-08]]\n",
            "Model 4 full accuracy:  0.8483466506004333\n",
            "--------------------------------\n",
            "Now loading model 4 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676842274_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 1s 8ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 10ms/step - loss: 1.4360 - accuracy: 0.7590\n",
            "[[9.99974489e-01 9.95276750e-08 1.04055025e-05 ... 4.80696781e-06\n",
            "  1.36139499e-06 6.96550069e-06]\n",
            " [9.74845171e-01 2.44315565e-02 2.04458993e-04 ... 4.15367598e-04\n",
            "  2.27778019e-05 3.74707270e-06]\n",
            " [6.12563838e-07 9.84464467e-01 1.40262824e-02 ... 1.86868754e-04\n",
            "  1.33600606e-05 5.10630116e-07]\n",
            " ...\n",
            " [9.98556077e-01 9.49356127e-06 1.42465101e-03 ... 3.94206108e-06\n",
            "  5.38224731e-06 2.66692126e-07]\n",
            " [7.49538158e-05 4.76842024e-06 4.28164261e-04 ... 8.10810179e-02\n",
            "  4.10243265e-05 2.27756063e-05]\n",
            " [9.62684921e-04 9.99003589e-01 1.16884857e-09 ... 2.91403612e-05\n",
            "  2.30418664e-06 1.28205414e-07]]\n",
            "Model 4 bagging accuracy:  0.7590270042419434\n",
            "--------------------------------\n",
            "Now loading model 4 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676842274_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 1s 9ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 1s 9ms/step - loss: 0.8936 - accuracy: 0.8263\n",
            "[[9.9999940e-01 3.5685736e-07 2.5472599e-07 ... 2.3541176e-08\n",
            "  7.9922984e-09 8.2432647e-09]\n",
            " [9.9999857e-01 6.9511685e-08 9.7160182e-07 ... 1.2326312e-07\n",
            "  4.1850887e-09 7.1785657e-09]\n",
            " [9.6966346e-09 1.0644202e-09 1.1764992e-07 ... 9.9999964e-01\n",
            "  1.1140426e-08 4.7159294e-09]\n",
            " ...\n",
            " [8.9154484e-05 5.0820600e-02 9.4556201e-01 ... 3.4987463e-03\n",
            "  1.8415375e-07 3.2783464e-07]\n",
            " [3.4897050e-05 9.6600527e-01 3.2447308e-02 ... 5.3597981e-04\n",
            "  4.5676152e-06 7.2784002e-07]\n",
            " [5.6824678e-01 2.7448460e-01 1.5707964e-01 ... 3.7351427e-05\n",
            "  1.4332213e-04 2.3116893e-06]]\n",
            "Model 4 blending accuracy:  0.8263018131256104\n",
            "--------------------------------\n",
            "Now loading model 5 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676913088_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 3s 26ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 29ms/step - loss: 0.4053 - accuracy: 0.9327\n",
            "[[9.9999976e-01 7.9944060e-09 8.2683842e-09 ... 7.2204120e-10\n",
            "  6.6278480e-09 2.0658251e-07]\n",
            " [4.9922976e-04 9.9949896e-01 7.9283490e-07 ... 9.3592678e-07\n",
            "  2.7431474e-08 4.3315584e-08]\n",
            " [3.3924807e-15 2.6212141e-09 1.0000000e+00 ... 4.8382517e-11\n",
            "  3.1524474e-13 5.1542151e-14]\n",
            " ...\n",
            " [9.9999857e-01 4.9034071e-07 6.8624490e-07 ... 1.2099236e-09\n",
            "  4.5553239e-08 1.6733850e-07]\n",
            " [5.4455626e-08 1.5919798e-09 1.3570282e-09 ... 1.0000000e+00\n",
            "  1.0392275e-10 3.8739603e-10]\n",
            " [1.5323767e-13 1.0000000e+00 2.6483849e-14 ... 3.0204471e-13\n",
            "  1.6460363e-17 3.4696700e-17]]\n",
            "Model 5 full accuracy:  0.932725191116333\n",
            "--------------------------------\n",
            "Now loading model 5 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676913088_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 3s 26ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 3s 28ms/step - loss: 0.8288 - accuracy: 0.8685\n",
            "[[9.99998212e-01 1.12722624e-07 1.62406127e-06 ... 1.76933899e-08\n",
            "  2.96978719e-10 6.92949209e-09]\n",
            " [8.68032314e-03 9.91319716e-01 4.95308221e-08 ... 1.05207820e-09\n",
            "  2.79576771e-08 5.30225597e-09]\n",
            " [9.50598003e-11 6.26842520e-05 9.99937296e-01 ... 1.95824379e-09\n",
            "  5.61690805e-10 5.74469118e-11]\n",
            " ...\n",
            " [9.99813616e-01 1.65808815e-04 1.65126694e-05 ... 8.85990858e-07\n",
            "  2.39104884e-06 6.84844451e-07]\n",
            " [5.17126397e-10 2.91994274e-06 1.59560720e-09 ... 9.99996662e-01\n",
            "  1.62712190e-08 6.82334189e-08]\n",
            " [4.15995960e-10 1.00000000e+00 3.85288112e-12 ... 2.91922085e-13\n",
            "  4.15406994e-13 5.05817922e-14]]\n",
            "Model 5 bagging accuracy:  0.8684910535812378\n",
            "--------------------------------\n",
            "Now loading model 5 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676913088_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 3s 27ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 3s 28ms/step - loss: 0.3841 - accuracy: 0.9274\n",
            "[[9.9999619e-01 5.4059992e-08 9.1783869e-09 ... 1.2070896e-10\n",
            "  6.8584086e-07 3.0906122e-06]\n",
            " [9.9999940e-01 1.9086976e-07 5.1591755e-08 ... 5.4950546e-09\n",
            "  2.9953934e-08 2.4813474e-07]\n",
            " [7.3107069e-11 2.2795361e-09 3.8706569e-11 ... 1.0000000e+00\n",
            "  1.0550840e-13 2.7106883e-10]\n",
            " ...\n",
            " [1.3882308e-14 1.3095867e-13 1.0000000e+00 ... 6.6004957e-10\n",
            "  1.5185619e-13 2.2349510e-13]\n",
            " [3.3232152e-07 9.9972636e-01 3.2665482e-06 ... 1.6812471e-08\n",
            "  2.6331720e-04 1.0043010e-09]\n",
            " [9.9920899e-01 7.8424619e-04 3.5870819e-06 ... 9.1916951e-07\n",
            "  4.1582450e-07 4.6146775e-07]]\n",
            "Model 5 blending accuracy:  0.9274040460586548\n",
            "--------------------------------\n",
            "Now loading model 6 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676936146_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 4s 30ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 30ms/step - loss: 0.9071 - accuracy: 0.8514\n",
            "[[1.00000000e+00 2.16339984e-11 1.02815305e-10 ... 5.56596827e-15\n",
            "  3.77581979e-14 1.83235639e-14]\n",
            " [2.19790302e-02 9.78020966e-01 2.93468050e-09 ... 7.25118784e-11\n",
            "  5.55885687e-13 1.02131140e-12]\n",
            " [2.23022822e-09 5.93410914e-05 9.99934912e-01 ... 1.42555567e-09\n",
            "  5.35520348e-06 2.12554307e-09]\n",
            " ...\n",
            " [9.95412648e-01 4.58706403e-03 3.93626209e-07 ... 6.32665240e-11\n",
            "  8.54004853e-11 2.42881914e-13]\n",
            " [9.74394061e-06 1.87732407e-08 1.36586590e-04 ... 9.99852300e-01\n",
            "  9.36876532e-09 1.33618960e-09]\n",
            " [4.96771726e-08 9.99990582e-01 2.11014442e-10 ... 9.45991724e-06\n",
            "  1.65651036e-15 2.85850149e-10]]\n",
            "Model 6 full accuracy:  0.8513873219490051\n",
            "--------------------------------\n",
            "Now loading model 6 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676936146_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 3s 27ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 30ms/step - loss: 1.2389 - accuracy: 0.7955\n",
            "[[1.0000000e+00 9.5118852e-12 1.5443400e-12 ... 4.2817396e-18\n",
            "  1.5140891e-15 1.6220617e-11]\n",
            " [5.3292043e-03 9.9467081e-01 1.4430171e-08 ... 7.3455664e-09\n",
            "  3.0967794e-11 9.4963379e-09]\n",
            " [3.7929733e-12 2.1971507e-06 9.9999785e-01 ... 5.3989903e-12\n",
            "  5.3934374e-10 2.0693509e-16]\n",
            " ...\n",
            " [9.9998069e-01 5.0528079e-06 1.4356122e-05 ... 4.2117947e-15\n",
            "  1.2062135e-08 1.3861396e-11]\n",
            " [1.1815275e-09 3.9232292e-10 4.8822561e-11 ... 9.9999976e-01\n",
            "  2.6206117e-14 5.4375400e-11]\n",
            " [1.8818428e-08 1.0000000e+00 1.0392445e-15 ... 9.5621271e-12\n",
            "  7.8955314e-20 4.8987714e-17]]\n",
            "Model 6 bagging accuracy:  0.7955150008201599\n",
            "--------------------------------\n",
            "Now loading model 6 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676936146_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 4s 32ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 30ms/step - loss: 0.6886 - accuracy: 0.8605\n",
            "[[1.00000000e+00 1.45340153e-12 1.72479989e-18 ... 0.00000000e+00\n",
            "  3.81501098e-15 6.75290003e-17]\n",
            " [1.00000000e+00 6.48459397e-10 7.65380315e-10 ... 3.75666220e-10\n",
            "  2.30451006e-10 4.99192299e-10]\n",
            " [1.07389438e-10 3.69293325e-08 2.40355891e-09 ... 1.00000000e+00\n",
            "  2.74412416e-12 1.83371679e-10]\n",
            " ...\n",
            " [5.72147728e-05 8.02535505e-05 9.99814332e-01 ... 4.81089628e-05\n",
            "  6.70774339e-11 1.07476616e-07]\n",
            " [1.68630195e-05 9.99976516e-01 4.62901926e-06 ... 1.21236441e-12\n",
            "  2.08409597e-06 2.54664744e-11]\n",
            " [9.97527778e-01 1.76293950e-03 7.09340151e-04 ... 6.28647481e-11\n",
            "  3.60053276e-09 3.88628227e-11]]\n",
            "Model 6 blending accuracy:  0.8605093359947205\n",
            "--------------------------------\n",
            "Now loading model 7 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676987763_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 10s 58ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 8s 47ms/step - loss: 0.3283 - accuracy: 0.9255\n",
            "[[1.00000000e+00 2.03547981e-30 1.70836319e-19 ... 2.87183215e-31\n",
            "  1.88050743e-31 9.62124835e-36]\n",
            " [5.20492578e-03 9.94793832e-01 1.19796402e-06 ... 3.02567948e-09\n",
            "  7.67334241e-16 6.35597640e-13]\n",
            " [1.88140596e-08 3.35062782e-06 9.99996662e-01 ... 1.84474137e-12\n",
            "  4.65862051e-08 1.31792584e-14]\n",
            " ...\n",
            " [9.99813497e-01 8.13053339e-05 1.05182815e-04 ... 3.15682369e-09\n",
            "  5.45351364e-09 2.05228664e-11]\n",
            " [3.03731063e-09 6.84018602e-08 6.24868657e-10 ... 9.99999881e-01\n",
            "  5.35505952e-14 7.56253671e-11]\n",
            " [5.90290540e-07 9.99999285e-01 1.95769113e-11 ... 1.12326653e-07\n",
            "  1.97589295e-18 9.00376202e-15]]\n",
            "Model 7 full accuracy:  0.9255036115646362\n",
            "--------------------------------\n",
            "Now loading model 7 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676987763_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 7s 38ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 10s 46ms/step - loss: 0.8050 - accuracy: 0.8582\n",
            "[[1.0000000e+00 1.8435978e-19 3.3315741e-16 ... 8.2638404e-29\n",
            "  1.4875067e-17 3.6797050e-17]\n",
            " [1.9166535e-05 9.9998081e-01 2.1678657e-10 ... 1.1543325e-11\n",
            "  2.3389615e-14 1.2308188e-15]\n",
            " [3.8610968e-05 5.2821815e-01 4.7086772e-01 ... 4.1922494e-08\n",
            "  8.7477214e-04 4.1382783e-10]\n",
            " ...\n",
            " [9.9994850e-01 2.9545878e-05 2.1795615e-05 ... 2.3615809e-11\n",
            "  8.5354145e-08 5.0816244e-12]\n",
            " [3.4897730e-05 2.4226298e-04 3.5549459e-07 ... 9.9969912e-01\n",
            "  7.6098789e-09 4.2911301e-09]\n",
            " [8.1768103e-06 9.9996591e-01 1.4357044e-09 ... 2.5856909e-05\n",
            "  5.4739499e-16 7.6689469e-13]]\n",
            "Model 7 bagging accuracy:  0.8582288026809692\n",
            "--------------------------------\n",
            "Now loading model 7 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676987763_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 8s 57ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 8s 43ms/step - loss: 0.3625 - accuracy: 0.9130\n",
            "[[1.00000000e+00 9.40884107e-11 2.13059778e-12 ... 2.12101802e-22\n",
            "  3.95830863e-14 2.61167405e-15]\n",
            " [1.00000000e+00 4.35412550e-09 2.85501928e-10 ... 2.79993287e-13\n",
            "  3.75639461e-15 3.44124798e-11]\n",
            " [1.30743860e-08 1.06527764e-09 1.06538025e-11 ... 1.00000000e+00\n",
            "  8.98195093e-15 1.46924411e-12]\n",
            " ...\n",
            " [5.70484597e-11 1.71575176e-09 1.00000000e+00 ... 2.06297743e-10\n",
            "  5.81612319e-18 1.07198952e-13]\n",
            " [1.92183606e-07 9.48724627e-01 8.09215067e-04 ... 1.60514460e-07\n",
            "  5.04656509e-02 4.86047457e-17]\n",
            " [1.00000000e+00 2.89757573e-09 4.17498676e-08 ... 9.74709135e-17\n",
            "  1.17746035e-09 3.94945714e-13]]\n",
            "Model 7 blending accuracy:  0.9129608273506165\n",
            "--------------------------------\n",
            "Now loading model 8 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676997761_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 5s 25ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 3s 21ms/step - loss: 0.7628 - accuracy: 0.8259\n",
            "[[9.9999952e-01 9.8189325e-08 2.0672692e-07 ... 1.4110314e-09\n",
            "  2.1668214e-08 1.0420093e-07]\n",
            " [1.7763844e-02 9.8201007e-01 1.5807967e-04 ... 5.9746184e-05\n",
            "  1.9234321e-06 1.9160868e-06]\n",
            " [1.5360419e-06 1.4526199e-05 9.9998021e-01 ... 8.5384090e-07\n",
            "  5.2056421e-08 5.6713265e-08]\n",
            " ...\n",
            " [9.8950702e-01 7.6176398e-03 1.5027750e-03 ... 6.0032653e-05\n",
            "  1.2413162e-03 2.5481049e-05]\n",
            " [1.4101903e-10 1.3345196e-07 1.5889916e-07 ... 9.9998736e-01\n",
            "  6.4120226e-10 7.7148471e-08]\n",
            " [2.3241912e-08 1.0000000e+00 8.8931510e-12 ... 3.9441464e-11\n",
            "  9.8091598e-13 2.2561207e-14]]\n",
            "Model 8 full accuracy:  0.8259217143058777\n",
            "--------------------------------\n",
            "Now loading model 8 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676997761_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 3s 18ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 4s 25ms/step - loss: 1.1756 - accuracy: 0.7575\n",
            "[[9.9999475e-01 2.7725579e-07 3.4801880e-07 ... 1.6621972e-09\n",
            "  1.6029672e-06 7.2389054e-07]\n",
            " [2.8075052e-03 9.9693358e-01 2.5709870e-04 ... 3.4937597e-07\n",
            "  8.6667008e-08 6.8914140e-08]\n",
            " [3.6016034e-05 9.9678175e-04 9.9896491e-01 ... 8.7600665e-09\n",
            "  1.3778905e-06 8.4596841e-10]\n",
            " ...\n",
            " [9.9301720e-01 6.9784373e-03 1.6145841e-06 ... 3.7589391e-08\n",
            "  2.6338680e-06 3.2833845e-09]\n",
            " [2.8962475e-06 8.3808061e-03 1.8462221e-04 ... 9.8912150e-01\n",
            "  2.9693823e-09 4.7212038e-07]\n",
            " [6.5267007e-03 9.9344593e-01 2.2506036e-07 ... 2.6869571e-05\n",
            "  1.4954205e-08 1.5978586e-09]]\n",
            "Model 8 bagging accuracy:  0.7575066685676575\n",
            "--------------------------------\n",
            "Now loading model 8 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1676997761_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 4s 26ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 5s 21ms/step - loss: 0.5986 - accuracy: 0.8624\n",
            "[[1.0000000e+00 1.6755908e-13 2.2159932e-10 ... 3.5602111e-25\n",
            "  8.8250629e-25 4.9758942e-18]\n",
            " [9.9999833e-01 6.1639423e-07 1.0144844e-06 ... 3.5174359e-12\n",
            "  7.8570657e-11 2.3751809e-09]\n",
            " [8.9196428e-09 1.6859160e-09 1.2953818e-08 ... 9.9999952e-01\n",
            "  4.0021545e-11 1.1886298e-08]\n",
            " ...\n",
            " [4.6326320e-05 1.2333662e-04 9.9981397e-01 ... 1.0914712e-05\n",
            "  5.3331632e-09 2.8053802e-07]\n",
            " [2.4517300e-04 9.8502582e-01 1.7647228e-04 ... 4.4680459e-05\n",
            "  1.4340887e-02 2.0021977e-05]\n",
            " [9.9988353e-01 1.1128155e-04 4.5068041e-06 ... 3.8877907e-08\n",
            "  9.2343882e-08 1.2044075e-07]]\n",
            "Model 8 blending accuracy:  0.8624097108840942\n",
            "--------------------------------\n",
            "Now loading model 9 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677017458_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 4s 40ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 3s 39ms/step - loss: 1.1136 - accuracy: 0.6906\n",
            "[[9.9990880e-01 2.2492121e-07 9.0795606e-05 ... 9.4883902e-15\n",
            "  5.9840914e-08 3.9066619e-10]\n",
            " [2.0241210e-01 7.6323766e-01 3.4325957e-02 ... 2.3242828e-05\n",
            "  4.0179731e-07 2.6647201e-10]\n",
            " [7.9220515e-03 4.4450665e-09 9.9207133e-01 ... 6.4218470e-06\n",
            "  3.7043593e-15 2.2494114e-14]\n",
            " ...\n",
            " [8.2379103e-01 9.9528633e-02 2.6868754e-06 ... 3.0617585e-08\n",
            "  7.6670647e-02 1.9332149e-09]\n",
            " [1.0132903e-02 9.4645940e-02 1.9161770e-01 ... 6.7068744e-01\n",
            "  8.0932215e-05 6.3516211e-04]\n",
            " [6.9914560e-04 9.9927849e-01 3.6583888e-06 ... 3.4238226e-06\n",
            "  4.8637250e-09 9.4244418e-11]]\n",
            "Model 9 full accuracy:  0.6906119585037231\n",
            "--------------------------------\n",
            "Now loading model 9 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677017458_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 3s 36ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 3s 38ms/step - loss: 1.1210 - accuracy: 0.6104\n",
            "[[9.7175884e-01 1.8751363e-03 2.5959877e-02 ... 4.2886327e-07\n",
            "  3.6373942e-05 3.6312593e-04]\n",
            " [7.1693283e-01 2.3897451e-01 4.3619674e-02 ... 1.4926765e-04\n",
            "  6.7703462e-05 9.5091993e-05]\n",
            " [3.2803815e-02 8.0989397e-01 1.5564990e-01 ... 1.6398326e-03\n",
            "  1.1848812e-05 3.9719332e-08]\n",
            " ...\n",
            " [9.8314083e-01 3.6090722e-03 1.1317792e-02 ... 7.5612597e-08\n",
            "  1.5904303e-03 1.3533833e-04]\n",
            " [1.5594051e-02 5.3147513e-02 7.8415051e-02 ... 1.2906884e-01\n",
            "  4.1018601e-04 6.6810682e-02]\n",
            " [2.8288141e-03 9.9606979e-01 1.0570239e-03 ... 2.5426155e-07\n",
            "  3.7135382e-05 4.6048720e-07]]\n",
            "Model 9 bagging accuracy:  0.6104142665863037\n",
            "--------------------------------\n",
            "Now loading model 9 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677017458_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 4s 42ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 3s 37ms/step - loss: 0.8992 - accuracy: 0.6697\n",
            "[[9.99973893e-01 2.58361142e-05 2.96013695e-07 ... 1.07615589e-15\n",
            "  2.73641554e-09 5.41171219e-10]\n",
            " [9.99995112e-01 2.16961166e-06 2.79653477e-06 ... 1.65843068e-11\n",
            "  1.33237432e-09 2.21690832e-10]\n",
            " [8.07247765e-04 5.32127991e-02 9.72868130e-02 ... 8.05289030e-01\n",
            "  5.44467584e-05 2.27592625e-02]\n",
            " ...\n",
            " [2.61359662e-01 6.47841692e-01 9.04245898e-02 ... 3.15969402e-04\n",
            "  8.67378822e-06 4.22702688e-05]\n",
            " [1.75576210e-02 9.73081112e-01 9.30541568e-03 ... 3.96053802e-05\n",
            "  1.13914230e-05 1.94084896e-06]\n",
            " [8.63002360e-01 1.26525015e-01 8.83687660e-03 ... 5.96349537e-06\n",
            "  1.19974815e-04 1.36937166e-03]]\n",
            "Model 9 blending accuracy:  0.6697073578834534\n",
            "--------------------------------\n",
            "Now loading model 10 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677026677_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 8s 44ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 8s 40ms/step - loss: 2.9519 - accuracy: 0.8590\n",
            "[[1.0000000e+00 3.5997328e-25 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [6.3888817e-03 9.9326742e-01 2.3055238e-05 ... 3.0018541e-04\n",
            "  8.9424779e-09 1.1591995e-05]\n",
            " [1.1705344e-10 1.6106099e-02 9.7966594e-01 ... 3.8399692e-09\n",
            "  9.5133919e-09 6.0905911e-09]\n",
            " ...\n",
            " [9.9949574e-01 4.8735063e-04 1.6864769e-05 ... 1.2552542e-11\n",
            "  1.0409694e-08 5.5713653e-13]\n",
            " [8.2526534e-11 5.1807514e-09 2.7891875e-09 ... 1.0000000e+00\n",
            "  1.9578144e-16 1.3016285e-12]\n",
            " [6.0145935e-04 9.9937648e-01 4.3381915e-06 ... 1.7488916e-05\n",
            "  4.6645774e-11 2.0614928e-08]]\n",
            "Model 10 full accuracy:  0.8589890003204346\n",
            "--------------------------------\n",
            "Now loading model 10 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677026677_bagging_model.h5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2122e84ea8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mm8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_holdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mm9\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_holdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mm10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_holdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-3978c579e53d>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(modelnumber, X_test, y_test, X_holdout, y_holdout)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mmodtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now loading model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_trained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"blending\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-fded1b1e6892>\u001b[0m in \u001b[0;36mload_trained_model\u001b[0;34m(modeltype, modelnumber)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_skin_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodeltype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelnumber\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m                         raise IOError(\n\u001b[0m\u001b[1;32m    228\u001b[0m                             \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                         )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/drive/MyDrive/Kaggle/skin_results/1677026677_bagging_model.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#m10 = generate_model(10, X_test, y_test, X_holdout, y_holdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X85kGPxCxuxH",
        "outputId": "197b844e-effa-4e27-e53a-e749498dacc7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now loading model 10 full\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677026677_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 61s 689ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 60s 671ms/step - loss: 2.9518 - accuracy: 0.8590\n",
            "[[9.9999994e-01 3.5996778e-25 0.0000000e+00 ... 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00]\n",
            " [6.3889064e-03 9.9326742e-01 2.3055085e-05 ... 3.0018430e-04\n",
            "  8.9424272e-09 1.1592128e-05]\n",
            " [1.1705299e-10 1.6105911e-02 9.7966611e-01 ... 3.8399408e-09\n",
            "  9.5133394e-09 6.0905694e-09]\n",
            " ...\n",
            " [9.9949574e-01 4.8734414e-04 1.6864671e-05 ... 1.2552351e-11\n",
            "  1.0409595e-08 5.5713225e-13]\n",
            " [8.2526534e-11 5.1807714e-09 2.7891609e-09 ... 1.0000000e+00\n",
            "  1.9577994e-16 1.3016260e-12]\n",
            " [6.0145510e-04 9.9937648e-01 4.3381833e-06 ... 1.7489032e-05\n",
            "  4.6645864e-11 2.0614729e-08]]\n",
            "Model 10 full accuracy:  0.8589890003204346\n",
            "--------------------------------\n",
            "Now loading model 10 bagging\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677026677_bagging_model.h5\n",
            "Now predicting on test set\n",
            "83/83 [==============================] - 59s 672ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 59s 682ms/step - loss: 1.1046 - accuracy: 0.7815\n",
            "[[9.99999940e-01 1.76122965e-17 3.47900483e-22 ... 2.86055471e-34\n",
            "  9.11144681e-34 1.01470530e-31]\n",
            " [4.58282046e-02 9.54171777e-01 5.71774761e-09 ... 2.97475911e-09\n",
            "  1.08279196e-13 5.96073451e-12]\n",
            " [5.75116701e-06 3.63818253e-03 9.83721197e-01 ... 7.76367262e-04\n",
            "  1.00179145e-03 7.19271384e-07]\n",
            " ...\n",
            " [1.00000000e+00 2.77163639e-11 1.88919172e-10 ... 2.06725052e-22\n",
            "  8.66047400e-19 1.80614719e-19]\n",
            " [9.41816907e-05 3.57867663e-07 3.21829901e-07 ... 9.99691844e-01\n",
            "  9.77874726e-11 6.77938374e-07]\n",
            " [2.76480387e-06 9.99989629e-01 7.48557980e-08 ... 7.54480061e-06\n",
            "  8.03756848e-15 9.38899091e-14]]\n",
            "Model 10 bagging accuracy:  0.781451940536499\n",
            "--------------------------------\n",
            "Now loading model 10 blending\n",
            "/content/drive/MyDrive/Kaggle/skin_results/1677026677_blending_model.h5\n",
            "Now predicting on holdout set\n",
            "84/84 [==============================] - 65s 721ms/step\n",
            "Now evaluating on test set\n",
            "83/83 [==============================] - 61s 689ms/step - loss: 0.5171 - accuracy: 0.8636\n",
            "[[9.9999994e-01 2.1214241e-13 1.9968630e-12 ... 1.2121159e-30\n",
            "  1.7536130e-18 3.2148084e-20]\n",
            " [9.9997407e-01 5.1163909e-07 2.5238709e-05 ... 6.4821419e-09\n",
            "  1.0896540e-11 1.1147990e-07]\n",
            " [2.0410831e-09 2.9610703e-09 4.3681043e-06 ... 9.9999553e-01\n",
            "  1.4825816e-11 7.1006714e-11]\n",
            " ...\n",
            " [5.2912156e-07 9.2062500e-04 9.9907696e-01 ... 1.9313161e-06\n",
            "  1.6367387e-12 1.3352081e-11]\n",
            " [9.1287311e-06 9.9531436e-01 4.6728812e-03 ... 8.4712341e-11\n",
            "  3.5853614e-06 1.2397555e-10]\n",
            " [8.2171392e-01 1.7815709e-01 1.2904684e-04 ... 4.5437449e-13\n",
            "  2.1437369e-08 1.1192307e-10]]\n",
            "Model 10 blending accuracy:  0.8635500073432922\n",
            "--------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#np.save(os.path.join(results_skin_dir,'model1'), m1)\n",
        "#np.save(os.path.join(results_skin_dir,'model2'), m2)\n",
        "#np.save(os.path.join(results_skin_dir,'model3'), m3)\n",
        "#np.save(os.path.join(results_skin_dir,'model4'), m4)\n",
        "#np.save(os.path.join(results_skin_dir,'model5'), m5)\n",
        "#np.save(os.path.join(results_skin_dir,'model6'), m6)\n",
        "#np.save(os.path.join(results_skin_dir,'model7'), m7)\n",
        "#np.save(os.path.join(results_skin_dir,'model8'), m8)\n",
        "#np.save(os.path.join(results_skin_dir,'model9'), m9)\n",
        "#np.save(os.path.join(results_skin_dir,'model10'), m10)"
      ],
      "metadata": {
        "id": "G2MpJx70MfI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578391c3-4147-45e9-a355-fbd0204137af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  arr = np.asanyarray(arr)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading lightweight stored model predictions"
      ],
      "metadata": {
        "id": "3AlGlZFwVRLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = np.load(os.path.join(results_skin_dir,'model1.npy'), allow_pickle=True)\n",
        "model1 = list(model1)\n",
        "\n",
        "model2 = np.load(os.path.join(results_skin_dir,'model2.npy'),allow_pickle=True)\n",
        "model2 = list(model2)\n",
        "\n",
        "model3 = np.load(os.path.join(results_skin_dir,'model3.npy'),allow_pickle=True)\n",
        "model3 = list(model3)\n",
        "\n",
        "model4 = np.load(os.path.join(results_skin_dir,'model4.npy'),allow_pickle=True)\n",
        "model4 = list(model4)\n",
        "\n",
        "model5 = np.load(os.path.join(results_skin_dir,'model5.npy'),allow_pickle=True)\n",
        "model5 = list(model5)\n",
        "\n",
        "model6 = np.load(os.path.join(results_skin_dir,'model6.npy'),allow_pickle=True)\n",
        "model6 = list(model6)\n",
        "\n",
        "model7 = np.load(os.path.join(results_skin_dir,'model7.npy'),allow_pickle=True)\n",
        "model7 = list(model7)\n",
        "\n",
        "model8 = np.load(os.path.join(results_skin_dir,'model8.npy'),allow_pickle=True)\n",
        "model8 = list(model8)\n",
        "\n",
        "model9 = np.load(os.path.join(results_skin_dir,'model9.npy'),allow_pickle=True)\n",
        "model9 = list(model9)\n",
        "\n",
        "model10 = np.load(os.path.join(results_skin_dir,'model10.npy'),allow_pickle=True)\n",
        "model10 = list(model10)"
      ],
      "metadata": {
        "id": "ii8ePfvRNee0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model helper functions"
      ],
      "metadata": {
        "id": "rRccnYzRVnTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#given class probabilities as y_pred and real labels as y_test\n",
        "def test_model(y_pred, y_test):\n",
        "    \"\"\" Tunning the accurate results and inaccurate results\n",
        "\n",
        "    Returns:\n",
        "        (total, accurate) [tuple]: tuple of total tested test-cases, accurate\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    accurate = 0\n",
        "    accurateindex = []\n",
        "    wrongindex = []\n",
        "    for i in range(len(y_pred)):\n",
        "        if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
        "            accurate += 1\n",
        "            accurateindex.append(i)\n",
        "        else:\n",
        "            wrongindex.append(i)\n",
        "        total += 1\n",
        "    return (total, accurate)"
      ],
      "metadata": {
        "id": "8FllQKTQfOZT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function that returns a 3D array where the first dimension is the model, and the other 2 are the predictions for each of the 7 classes\n",
        "#this will be used for both voting and generating the training data for the metalearner through holdout set predictions\n",
        "#where models is the list of models as generated by generate_models\n",
        "#and modeltype is either \n",
        "\n",
        "#the models will be inputted into the GA as follows:\n",
        "#list: [model_name, predictions_test, accuracy_full, bagging_predictions_test, bagging_accuracy, blending_predictions_holdout, bagging_accuracy]\n",
        "#model[0]: model name\n",
        "\n",
        "#the prediction index in the model generated by generate_model\n",
        "def get_pred_idx(modtype):\n",
        "    if modtype == \"full\":\n",
        "        return 1\n",
        "    elif modtype == \"bagging\":\n",
        "        return 3\n",
        "    elif modtype == \"blending\":\n",
        "        return 5\n",
        "\n",
        "#the accuracy index in the model generated by generate_model\n",
        "def get_acc_idx(modtype):\n",
        "    if modtype == \"full\":\n",
        "        return 2\n",
        "    elif modtype == \"bagging\":\n",
        "        return 4\n",
        "    elif modtype == \"blending\":\n",
        "        return 6\n",
        "\n",
        "def get_accuracies(models, model_type):\n",
        "  num_models = len(models)\n",
        "  test_accuracies = []\n",
        "  idx = get_acc_idx(model_type)\n",
        "  for m in models:\n",
        "    test_accuracies.append(m[idx])\n",
        "  return test_accuracies\n",
        "\n",
        "def get_normalized_accuracies(models, model_type):\n",
        "  accs = get_accuracies(models, model_type)\n",
        "  normalized_accs=[float(i)/sum(accs) for i in accs]\n",
        "  return normalized_accs\n",
        "\n",
        "#models is a list of generate_model lists\n",
        "def join_model_predictions(models, y_test, y_holdout, model_type):\n",
        "  num_models = len(models)\n",
        "  num_classes = y_test.shape[1]\n",
        "  if model_type==\"full\" or model_type==\"bagging\":\n",
        "    num_instances = y_test.shape[0]\n",
        "  if model_type==\"blending\":  \n",
        "    num_instances = y_holdout.shape[0]\n",
        "    \n",
        "  joined_preds = np.zeros(shape=(num_models, num_instances, num_classes))\n",
        "  idx = int(get_pred_idx(model_type))\n",
        "  count=0\n",
        "  for i in models:\n",
        "    #print(i[idx])\n",
        "    joined_preds[count]=i[idx]\n",
        "    count=count+1  \n",
        "  return joined_preds"
      ],
      "metadata": {
        "id": "FUVul8pTimkh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#models is a list of generate_model lists\n",
        "#joins the predictions as crisp class labels rather than predictions\n",
        "\n",
        "def join_model_predictions_crisp(models, y_test, y_holdout, model_type):\n",
        "  num_models = len(models)\n",
        "  num_classes = y_test.shape[1]\n",
        "  if model_type==\"full\" or model_type==\"bagging\":\n",
        "    num_instances = y_test.shape[0]\n",
        "  if model_type==\"blending\":  \n",
        "    num_instances = y_holdout.shape[0]\n",
        "    \n",
        "  joined_preds = np.zeros(shape=(num_models, num_instances, num_classes))\n",
        "  idx = int(get_pred_idx(model_type))\n",
        "  count=0\n",
        "  for i in models:\n",
        "    y_preds=i[idx]\n",
        "    #print(y_preds)\n",
        "    modelpreds=np.zeros_like(y_preds)\n",
        "    modelpreds[np.arange(len(y_preds)), y_preds.argmax(1)] = 1\n",
        "    #print(modelpreds)\n",
        "    joined_preds[count]=modelpreds\n",
        "    count=count+1  \n",
        "  return joined_preds"
      ],
      "metadata": {
        "id": "8O0zf8bcZY8u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#given a list of model lists (defined with the generate_model function), gets the soft voting accuracy\n",
        "#for full and bagging\n",
        "#mtype = \"full\" or \"bagging\"\n",
        "def soft_voting(models, mtype, y_test, y_holdout):\n",
        "    if mtype==\"full\":\n",
        "      preds = join_model_predictions(models, y_test, y_holdout, \"full\")\n",
        "    if mtype==\"bagging\":\n",
        "      preds = join_model_predictions(models, y_test, y_holdout, \"bagging\")\n",
        "    y_pred = np.mean(np.array(preds), axis=0)\n",
        "    results = test_model(y_pred, y_test)\n",
        "    accuracy = results[1]/results[0]\n",
        "    print('Soft voting accuracy: ', accuracy)\n",
        "    return accuracy\n",
        "\n",
        "def weighted_soft_voting(models, mtype, y_test, y_holdout):\n",
        "    if mtype==\"full\":\n",
        "      preds = join_model_predictions(models, y_test, y_holdout, \"full\")\n",
        "    if mtype==\"bagging\":\n",
        "      preds = join_model_predictions(models, y_test, y_holdout, \"bagging\")\n",
        "    accuracies = get_accuracies(models, mtype)\n",
        "    y_pred = np.average(np.array(preds), axis=0, weights=accuracies)\n",
        "    results = test_model(y_pred, y_test)\n",
        "    accuracy = results[1]/results[0]\n",
        "    print('Weighted soft voting accuracy: ', accuracy)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "-j-HZY7RmIii"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#given a list of model lists (defined with the generate_model function), gets the hard voting accuracy\n",
        "#for full and bagging\n",
        "#mtype = \"full\" or \"bagging\"\n",
        "\n",
        "def hard_voting(models, mtype, y_test, y_holdout):\n",
        "    if mtype==\"full\":\n",
        "      preds = join_model_predictions_crisp(models, y_test, y_holdout, \"full\")\n",
        "    if mtype==\"bagging\":\n",
        "      preds = join_model_predictions_crisp(models, y_test, y_holdout, \"bagging\")\n",
        "    y_pred = np.sum(np.array(preds), axis=0)\n",
        "    results = test_model(y_pred, y_test)\n",
        "    accuracy = results[1]/results[0]\n",
        "    print('Hard voting accuracy: ', accuracy)\n",
        "    return accuracy\n",
        "\n",
        "def weighted_hard_voting(models, mtype, y_test, y_holdout):\n",
        "    if mtype==\"full\":\n",
        "      preds = join_model_predictions_crisp(models, y_test, y_holdout, \"full\")\n",
        "    if mtype==\"bagging\":\n",
        "      preds = join_model_predictions_crisp(models, y_test, y_holdout, \"bagging\")\n",
        "    accs = get_normalized_accuracies(models, mtype)\n",
        "    weights = np.array(accs)\n",
        "    weighted_preds = preds*weights[:,np.newaxis, np.newaxis]\n",
        "    y_pred = np.sum(np.array(weighted_preds), axis=0)\n",
        "    results = test_model(y_pred, y_test)\n",
        "    accuracy = results[1]/results[0]\n",
        "    print('Weighted hard voting accuracy: ', accuracy)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "auu_Fcocj9XP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generates the predictions in a format to be fed to the metalearner either for training where mtype=\"blending\" or to test the metalearner where mtype=\"full\"\n",
        "#since in blending, models are later refit on the full data\n",
        "\n",
        "def get_prediction_set_crisp(models, y_test, y_holdout, mtype):\n",
        "  preds = join_model_predictions_crisp(models, y_test, y_holdout, mtype)\n",
        "  labels = []\n",
        "  for m in preds:\n",
        "    class_labels = np.argmax(m, axis=1)\n",
        "    class_labels = class_labels.reshape(len(class_labels), 1)\n",
        "    labels.append(class_labels)\n",
        "  return np.hstack(labels)"
      ],
      "metadata": {
        "id": "NgvZvUjJGItA"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#given a meta-learner as \"blender\", builds an ensemble with the models and gets the test accuracy\n",
        "def blend(blender, models, y_test, y_holdout):\n",
        "  meta_X = get_prediction_set_crisp(models, y_test, y_holdout, \"blending\")\n",
        "  test_X = get_prediction_set_crisp(models, y_test, y_holdout, \"full\")\n",
        "  blender.fit(meta_X, np.argmax(y_holdout, axis=1))\n",
        "  accuracy = blender.score(test_X,np.argmax(y_test, axis=1))\n",
        "  print(\"meta-learner: \", blender)\n",
        "  print(\"blending test accuracy: \", accuracy)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "lEr3b5W4Jzuy"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4iA_kbARc9OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model1, model2, model3, model4, model5, model6, model7, model10]\n",
        "weighted_hard_voting(models, \"full\", y_test, y_holdout)\n",
        "hard_voting(models, \"full\", y_test, y_holdout)\n",
        "weighted_soft_voting(models, \"full\", y_test, y_holdout)\n",
        "soft_voting(models, \"full\", y_test, y_holdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQlBzUoxT7Bv",
        "outputId": "ee108917-0510-4cb5-a161-bac9c16e6298"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted hard voting accuracy:  0.9494488787533257\n",
            "Hard voting accuracy:  0.943747624477385\n",
            "Weighted soft voting accuracy:  0.9505891296085138\n",
            "Soft voting accuracy:  0.9483086278981376\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9483086278981376"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models=[model1, model2, model3, model4, model5, model6, model7, model8, model9, model10]"
      ],
      "metadata": {
        "id": "cFKKYCLBJEMi"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blender = LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 300)\n",
        "blend(blender, models, y_test, y_holdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__VxEKfoJz0T",
        "outputId": "eaceb02d-3447-44b9-833c-01a1695c9055"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta-learner:  LogisticRegression(max_iter=300, multi_class='multinomial')\n",
            "blending test accuracy:  0.9137210186240973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9137210186240973"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrmodel = LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 200)\n",
        "svckernel =  SVC(gamma ='auto', probability = True)\n",
        "treemodel =  DecisionTreeClassifier()\n",
        "knn = KNeighborsClassifier(7)\n",
        "svclinear =  SVC(kernel=\"linear\", C=0.025, probability=True)\n",
        "gpc = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
        "rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
        "mlpc = MLPClassifier(alpha=1, max_iter=1000)\n",
        "ada = AdaBoostClassifier()\n",
        "gauss =GaussianNB()\n",
        "quad = QuadraticDiscriminantAnalysis()\n",
        "\n",
        "blenders = [lrmodel, svckernel, treemodel, knn, svclinear, rf, mlpc, ada, gauss, quad]"
      ],
      "metadata": {
        "id": "VJtOKhjPR27w"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for b in blenders:\n",
        "  blend(b, models, y_test, y_holdout)\n",
        "  print(\"_________________\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieJb5MgnOpP8",
        "outputId": "7b06f386-eaad-46f1-f487-828ac55dd297"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meta-learner:  LogisticRegression(max_iter=200, multi_class='multinomial')\n",
            "blending test accuracy:  0.9160015203344736\n",
            "_________________\n",
            "meta-learner:  SVC(gamma='auto', probability=True)\n",
            "blending test accuracy:  0.9289243633599392\n",
            "_________________\n",
            "meta-learner:  DecisionTreeClassifier()\n",
            "blending test accuracy:  0.9232231090839985\n",
            "_________________\n",
            "meta-learner:  KNeighborsClassifier(n_neighbors=7)\n",
            "blending test accuracy:  0.9266438616495629\n",
            "_________________\n",
            "meta-learner:  SVC(C=0.025, kernel='linear', probability=True)\n",
            "blending test accuracy:  0.9080197643481566\n",
            "_________________\n",
            "meta-learner:  RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)\n",
            "blending test accuracy:  0.9243633599391866\n",
            "_________________\n",
            "meta-learner:  MLPClassifier(alpha=1, max_iter=1000)\n",
            "blending test accuracy:  0.9315849486887116\n",
            "_________________\n",
            "meta-learner:  AdaBoostClassifier()\n",
            "blending test accuracy:  0.8608893956670467\n",
            "_________________\n",
            "meta-learner:  GaussianNB()\n",
            "blending test accuracy:  0.9220828582288103\n",
            "_________________\n",
            "meta-learner:  QuadraticDiscriminantAnalysis()\n",
            "blending test accuracy:  0.8764728240212847\n",
            "_________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blend(blender, models, y_test, y_holdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ajTKsuwOECU",
        "outputId": "f470926a-ee10-4070-d645-0e19e93e15c7"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9258836944127709"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GA"
      ],
      "metadata": {
        "id": "btOPRgpZfPrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#same function, different parameter\n",
        "\n",
        "#1) soft_voting\n",
        "#2) bagging_soft_voting\n",
        "#3) weighted_soft_voting\n",
        "#4) bagging_weighted_soft_voting\n",
        "\n",
        "#5) hard_voting\n",
        "#6) bagging_hard_voting\n",
        "#7) weighted_hard_voting\n",
        "#8) bagging_weighted_hard_voting\n",
        "\n",
        "#blending_LR\n",
        "#blending_SVCK\n",
        "#blending_tree\n",
        "#blending_knn\n",
        "#blending_SVCL\n",
        "#blending_GPC\n",
        "#blending_RF\n",
        "#blending_MLPC\n",
        "#blending_ADA\n",
        "#blending_gauss\n",
        "#blending_quad\n",
        "\n",
        "#metalearners for blending\n",
        "#lrmodel = ('LR',LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 200))\n",
        "#svckernel = ('SVC', SVC(gamma ='auto', probability = True))\n",
        "#treemodel = ('DTC', DecisionTreeClassifier())\n",
        "#knn = ('KNN', KNeighborsClassifier(7))\n",
        "#svclinear = ('SVCL', SVC(kernel=\"linear\", C=0.025, probability=True))\n",
        "#gpc = ('GPC',GaussianProcessClassifier(1.0 * RBF(1.0)))\n",
        "#rf = ('RF',RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1))\n",
        "#mlpc = ('MLPC',MLPClassifier(alpha=1, max_iter=1000))\n",
        "#ada = ('ADA',AdaBoostClassifier())\n",
        "#gauss = ('GAUSS',GaussianNB())\n",
        "#quad = ('QUAD',QuadraticDiscriminantAnalysis())"
      ],
      "metadata": {
        "id": "VMMvyAdWkdFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GA helper functions"
      ],
      "metadata": {
        "id": "QTtvGAMqfS1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#chromosome_architecture defines the structure of the chromosome given the list of models and mechanisms \n",
        "#start and end indices\n",
        "#adaptable to any number of mechanisms\n",
        "\n",
        "def chromosome_architecture(models, mechanisms):\n",
        "  #since models are binary encoded depending on their index, the length of the model portion of the chromosome is equal to the number of potential models\n",
        "  model_bits = len(models)\n",
        "\n",
        "  #mechanism bits will be the bits needed to represent x mechanisms\n",
        "  #since there can only be 1 mechanism chosen per ensemble\n",
        "  #so we do one-hot encoding\n",
        "\n",
        "  mechanism_bits = len(mechanisms).bit_length()\n",
        "\n",
        "  #dictionaries that can get mechanism from its number and vice versa\n",
        "  mechanism_to_int = dict((m, i) for i, m in enumerate(mechanisms))\n",
        "  int_to_mechanism = dict((i, m) for i, m in enumerate(mechanisms))\n",
        "\n",
        "  #total chromosome length\n",
        "  total_chromosome_length = model_bits+ mechanism_bits\n",
        "\n",
        "  #prints and returns the specified parameters\n",
        "  print(model_bits, mechanism_bits, mechanism_to_int, int_to_mechanism, total_chromosome_length)\n",
        "  return model_bits, mechanism_bits, mechanism_to_int, int_to_mechanism, total_chromosome_length\n",
        "\n",
        "\n",
        "\n",
        "#given a chromosome (list of binary numbers), and chromosome architectur, decode into ensemble parameters\n",
        "#returns a tuple wher [0] = list of models used and [1] = ensemble mechanism\n",
        "\n",
        "def chromosome_decoder(chromosome, chromosome_architecture):\n",
        "\n",
        "  model_bits = chromosome_architecture[0]\n",
        "  mechanism_bits = chromosome_architecture[1]\n",
        "  mechanism_to_int = chromosome_architecture[2]\n",
        "  int_to_mechanism = chromosome_architecture[3]\n",
        "\n",
        "  model_portion = chromosome[0:model_bits]\n",
        "\n",
        "  mechanism_start = model_bits\n",
        "  mechanism_end = model_bits+mechanism_bits\n",
        "  mechanism_portion = chromosome[mechanism_start:mechanism_end]\n",
        "  print('model encoding: ', model_portion)\n",
        "  print('mechanism encoding: ', mechanism_portion)\n",
        "\n",
        "  print(\"MODELS: \")\n",
        "  models_used = []\n",
        "  for idx, i in enumerate(model_portion):\n",
        "    if i==1:\n",
        "      print(models[idx])\n",
        "      models_used.append(models[idx])\n",
        "  \n",
        "  print(\"Mechanism: \")\n",
        "  #get the mechanism as a binary string\n",
        "  mechanism_code = ''.join([str(x) for x in mechanism_portion])\n",
        "\n",
        "  #have the program raise an exception for illegal mechanism coding\n",
        "  #example: we have 10 mechanisms --> 9 binary numbers (+0) so 10 possibilities\n",
        "  #4 bits needed to cover 10 possibilities\n",
        "  #last legal binary number is 1001\n",
        "  #1011, 1101, 1111... etc all illegal\n",
        "\n",
        "  try:\n",
        "    #transform binary mechanism code to int, and check in dictionary\n",
        "    mechanism_name = int_to_mechanism[int(mechanism_code, 2)]\n",
        "  except:\n",
        "    #if not found, then the individual is illegal\n",
        "      raise Exception(\"Mechanism out of bounds\")\n",
        "      return -1\n",
        "  else:\n",
        "    print(mechanism_name)\n",
        "    return models_used, mechanism_name"
      ],
      "metadata": {
        "id": "EWocbdClfRTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GA Set-Up"
      ],
      "metadata": {
        "id": "VQCmEwoJhOTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VARIABLES\n",
        "\n",
        "#ALREADY TRAINED MODELS\n",
        "\n",
        "models = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10]\n",
        "\n",
        "mechanisms = ['soft_voting', 'hard_voting']"
      ],
      "metadata": {
        "id": "FbK9aNmhhIkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NON VARIABLE\n",
        "\n",
        "arch = chromosome_architecture(models, mechanisms)\n",
        "\n",
        "def fitness_func(solution, solution_idx):\n",
        "  print(\"--------------\")\n",
        "  print('solution: ', solution)\n",
        "  try:\n",
        "    #if the mechanism chosen is out of bounds (not valid) --> fitness = -1\n",
        "    #or if all model portion bits are 0 --> none selected\n",
        "    #the chromosome_decoder will throw an exception\n",
        "    #which will be caught here and result in a fitness = -1\n",
        "    parameters = chromosome_decoder(solution, arch)\n",
        "  except:\n",
        "    print('illegal individual - mechanism out of bounds')\n",
        "    return -1 #negative fitness, so it is discounted for future generations\n",
        "\n",
        "  if len(parameters[0])==0:\n",
        "    print('illegal individual - no model selected')\n",
        "    return -1\n",
        "\n",
        "  models = parameters[0]\n",
        "  mechanism = parameters[1]\n",
        "\n",
        "  # Ensemble of Models \n",
        "  estimator = models\n",
        "\n",
        "  #NEED TO DEFINE DATA BEFORE RUNNING THIS\n",
        "\n",
        "  #print('ENSEMBLE')\n",
        "  if mechanism == 'hard_voting':\n",
        "    hard_voting = VotingClassifier(estimators = estimator, voting ='hard') \n",
        "    hard_voting.fit(X_train, y_train) \n",
        "    y_pred = hard_voting.predict(X_test)\n",
        "    #print(y_pred)\n",
        "    #print(y_test)\n",
        "    hardscore = accuracy_score(y_test, y_pred) \n",
        "    #print(\"Hard Voting Score\", hardscore) \n",
        "    print('fitness: ', hardscore)\n",
        "    return hardscore\n",
        "\n",
        "  if mechanism == 'soft_voting':\n",
        "\n",
        "    softvoting = VotingClassifier(estimators = estimator, voting ='soft') \n",
        "    softvoting.fit(X_train, y_train) \n",
        "    y_pred = softvoting.predict(X_test)\n",
        "    #print(y_pred)\n",
        "    #print(y_test)\n",
        "    softscore = accuracy_score(y_test, y_pred) \n",
        "    #print(\"Soft Voting Score \", score2) \n",
        "    print('fitness: ', softscore)\n",
        "    return softscore\n"
      ],
      "metadata": {
        "id": "-w5JhrdUhd1x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}